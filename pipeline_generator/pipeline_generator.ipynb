{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:26:43.164726200Z",
     "start_time": "2023-07-15T18:26:43.156728400Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import uuid\n",
    "from datetime import datetime\n",
    "from typing import Tuple, Any, List, Dict\n",
    "\n",
    "from pyshacl import validate\n",
    "\n",
    "from common import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Pipeline generation algorithm"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ontology = get_ontology_graph()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:34.839287100Z",
     "start_time": "2023-07-15T18:22:33.311287300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1. Obtain Intent Information functions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T13:00:50.458486Z",
     "start_time": "2023-07-15T13:00:50.270487Z"
    }
   },
   "outputs": [],
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_intent_iri(intent_graph):\n",
    "    intent_iri_query = f\"\"\"\n",
    "PREFIX dtbox: <{dtbox}>\n",
    "SELECT ?iri\n",
    "WHERE {{\n",
    "    ?iri a dtbox:Intent .\n",
    "}}\n",
    "\"\"\"\n",
    "    result = intent_graph.query(intent_iri_query).bindings\n",
    "    assert len(result) == 1\n",
    "    return result[0]['iri']\n",
    "\n",
    "\n",
    "def get_intent_dataset_problem(intent_graph, intent_iri):\n",
    "    dataset_problem_query = f\"\"\"\n",
    "    PREFIX dtbox: <{dtbox}>\n",
    "    SELECT ?dataset ?problem\n",
    "    WHERE {{\n",
    "        {intent_iri.n3()} a dtbox:Intent .\n",
    "        {intent_iri.n3()} dtbox:overData ?dataset .\n",
    "        {intent_iri.n3()} dtbox:tackles ?problem .\n",
    "    }}\n",
    "\"\"\"\n",
    "    result = intent_graph.query(dataset_problem_query).bindings[0]\n",
    "    return result['dataset'], result['problem']\n",
    "\n",
    "\n",
    "def get_intent_params(intent_graph, intent_iri):\n",
    "    params_query = f\"\"\"\n",
    "    PREFIX dtbox: <{dtbox}>\n",
    "    SELECT ?param ?value\n",
    "    WHERE {{\n",
    "        {intent_iri.n3()} a dtbox:UserIntent .\n",
    "        {intent_iri.n3()} dtbox:usingParameter ?param_value .\n",
    "        ?param_value dtbox:forParameter ?param .\n",
    "        ?param_value dtbox:has_value ?value .\n",
    "    }}\n",
    "\"\"\"\n",
    "    result = intent_graph.query(params_query).bindings\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_intent_info(intent_graph, intent_iri=None) -> Tuple[Any, Any, List[Any], Any]:\n",
    "    if not intent_iri:\n",
    "        intent_iri = get_intent_iri(intent_graph)\n",
    "\n",
    "    dataset, problem = get_intent_dataset_problem(intent_graph, intent_iri)\n",
    "    params = get_intent_params(intent_graph, intent_iri)\n",
    "\n",
    "    return dataset, problem, params, intent_iri"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:34.857520900Z",
     "start_time": "2023-07-15T18:22:34.843286800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Obtain Loader functions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T13:00:55.379704800Z",
     "start_time": "2023-07-15T13:00:55.359705Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nee3a405cc25d4048bd7801084c90ab48b101 http://www.w3.org/1999/02/22-rdf-syntax-ns#type https://diviloper.dev/ontology#IOSpec\n",
      "nee3a405cc25d4048bd7801084c90ab48b101 https://diviloper.dev/ontology#hasTag https://diviloper.dev/ontology/shapes#LabeledTabularDatasetShape\n",
      "nee3a405cc25d4048bd7801084c90ab48b101 https://diviloper.dev/ontology#has_position 0\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:34.875285300Z",
     "start_time": "2023-07-15T18:22:34.855285900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Obtain Main component dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_implementation_input_specs(ontology, implementation):\n",
    "    input_spec_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?shape\n",
    "        WHERE {{\n",
    "            {implementation.n3()} dtbox:specifiesInput ?spec .\n",
    "            ?spec a dtbox:IOSpec ;\n",
    "                dtbox:hasTag ?shape ;\n",
    "                dtbox:has_position ?position .\n",
    "            ?shape a dtbox:DataTag .\n",
    "        }}\n",
    "        ORDER BY ?position\n",
    "    \"\"\"\n",
    "    results = ontology.query(input_spec_query).bindings\n",
    "    shapes = [flatten_shape(ontology, result['shape']) for result in results]\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def get_implementation_output_specs(ontology, implementation):\n",
    "    output_spec_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?shape\n",
    "        WHERE {{\n",
    "            {implementation.n3()} dtbox:specifiesOutput ?spec .\n",
    "            ?spec a dtbox:IOSpec ;\n",
    "                dtbox:hasTag ?shape ;\n",
    "                dtbox:has_position ?position .\n",
    "            ?shape a dtbox:DataTag .\n",
    "        }}\n",
    "        ORDER BY ?position\n",
    "    \"\"\"\n",
    "    results = ontology.query(output_spec_query).bindings\n",
    "    shapes = [flatten_shape(ontology, result['shape']) for result in results]\n",
    "    return shapes\n",
    "\n",
    "\n",
    "def flatten_shape(graph, shape):\n",
    "    if (shape, SH['and'], None) in graph:\n",
    "        subshapes_query = f\"\"\"\n",
    "            PREFIX sh: <{SH}>\n",
    "            PREFIX rdf: <{RDF}>\n",
    "\n",
    "            SELECT ?subshape\n",
    "            WHERE {{\n",
    "                {shape.n3()} sh:and ?andNode .\n",
    "                ?andNode rdf:rest*/rdf:first ?subshape .\n",
    "            }}\n",
    "        \"\"\"\n",
    "        subshapes = graph.query(subshapes_query).bindings\n",
    "\n",
    "        return [x for subshape in subshapes for x in flatten_shape(graph, subshape['subshape'])]\n",
    "    else:\n",
    "        return [shape]\n",
    "\n",
    "\n",
    "def get_potential_implementations(ontology, problem_iri, intent_parameters=None) -> List[Tuple[Any, List[Any]]]:\n",
    "    if intent_parameters is None:\n",
    "        intent_parameters = []\n",
    "    intent_params_match = [f'dtbox:hasParameter {param.n3()} ;' for param in intent_parameters]\n",
    "    intent_params_separator = '            \\n'\n",
    "    main_implementation_query = f\"\"\"\n",
    "    PREFIX dtbox: <{dtbox}>\n",
    "    SELECT ?implementation\n",
    "    WHERE {{\n",
    "        ?implementation a dtbox:Implementation ;\n",
    "            {intent_params_separator.join(intent_params_match)}\n",
    "            dtbox:implements ?algorithm .\n",
    "        ?algorithm a dtbox:Algorithm ;\n",
    "            dtbox:solves ?problem .\n",
    "        ?problem dtbox:subProblemOf* {problem_iri.n3()} .\n",
    "        FILTER NOT EXISTS{{\n",
    "            ?implementation a dtbox:ApplierImplementation.\n",
    "        }}\n",
    "    }}\n",
    "\"\"\"\n",
    "    results = ontology.query(main_implementation_query).bindings\n",
    "    implementations = [result['implementation'] for result in results]\n",
    "\n",
    "    implementations_with_shapes = [\n",
    "        (implementation, get_implementation_input_specs(ontology, implementation))\n",
    "        for implementation in implementations]\n",
    "\n",
    "    return implementations_with_shapes\n",
    "\n",
    "\n",
    "def get_component_implementation(ontology, component):\n",
    "    implementation_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?implementation\n",
    "        WHERE {{\n",
    "            {component.n3()} dtbox:hasImplementation ?implementation .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    result = ontology.query(implementation_query).bindings\n",
    "    assert len(result) == 1\n",
    "    return result[0]['implementation']\n",
    "\n",
    "\n",
    "def get_implementation_components(ontology, implementation) -> List[Any]:\n",
    "    components_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?component\n",
    "        WHERE {{\n",
    "            ?component dtbox:hasImplementation {implementation.n3()} .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    results = ontology.query(components_query).bindings\n",
    "    return [result['component'] for result in results]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:34.884287100Z",
     "start_time": "2023-07-15T18:22:34.879286800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def find_components_to_satisfy_shape(ontology, shape, only_learners=True):\n",
    "    implementation_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?implementation\n",
    "        WHERE {{\n",
    "            ?implementation a dtbox:{'Learner' if only_learners else ''}Implementation ;\n",
    "                dtbox:specifiesOutput ?spec .\n",
    "            ?spec dtbox:hasTag {shape.n3()} .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    result = ontology.query(implementation_query).bindings\n",
    "    implementations = [x['implementation'] for x in result]\n",
    "    components = [c\n",
    "                  for implementation in implementations\n",
    "                  for c in get_implementation_components(ontology, implementation)]\n",
    "    return components"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:34.908286400Z",
     "start_time": "2023-07-15T18:22:34.887285500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def identify_data_io(ontology: Graph, ios: List[Any], return_index=False) -> Any:\n",
    "    for i, io_shapes in enumerate(ios):\n",
    "        for io_shape in io_shapes:\n",
    "            if (io_shape, SH.targetClass, dmop.TabularDataset) in ontology:\n",
    "                return i if return_index else io_shapes\n",
    "\n",
    "\n",
    "def identify_model_io(ontology: Graph, ios: List[Any], return_index=False) -> Any:\n",
    "    for i, io_shapes in enumerate(ios):\n",
    "        for io_shape in io_shapes:\n",
    "            query = f'''\n",
    "    PREFIX sh: <{SH}>\n",
    "    PREFIX rdfs: <{RDFS}>\n",
    "    PREFIX ddata: <{dd}>\n",
    "\n",
    "    ASK {{\n",
    "      {{\n",
    "        {io_shape.n3()} sh:targetClass ?targetClass .\n",
    "        ?targetClass rdfs:subClassOf* ddata:Model .\n",
    "      }}\n",
    "      UNION\n",
    "      {{\n",
    "        {io_shape.n3()} rdfs:subClassOf* ddata:Model .\n",
    "      }}\n",
    "    }}\n",
    "'''\n",
    "            if ontology.query(query).askAnswer:\n",
    "                return i if return_index else io_shapes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:34.916286Z",
     "start_time": "2023-07-15T18:22:34.905285900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Component: https://diviloper.dev/ontology/ABOX#component-decimal_scaling\n",
      "Implementation: https://diviloper.dev/ontology/ABOX#implementation-normalizer_(pmml)\n",
      "Specs: [[rdflib.term.URIRef('https://diviloper.dev/ontology/shapes#NormalizedTabularDatasetShape')], [rdflib.term.URIRef('https://diviloper.dev/ontology/shapes#NormalizerModel')]]\n",
      "Model spec: [rdflib.term.URIRef('https://diviloper.dev/ontology/shapes#NormalizerModel')]\n"
     ]
    }
   ],
   "source": [
    "comp = dabox.term('component-decimal_scaling')\n",
    "print(f'Component: {comp}')\n",
    "impl = get_component_implementation(ontology, comp)\n",
    "print(f'Implementation: {impl}')\n",
    "specs = get_implementation_output_specs(ontology, impl)\n",
    "print(f'Specs: {specs}')\n",
    "model_spec = identify_model_io(ontology, specs)\n",
    "print(f'Model spec: {model_spec}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.089570900Z",
     "start_time": "2023-07-15T18:22:34.918288900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://diviloper.dev/ontology/shapes#NormalizerModel http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://www.w3.org/ns/shacl#NodeShape\n",
      "https://diviloper.dev/ontology/shapes#NormalizerModel http://www.w3.org/1999/02/22-rdf-syntax-ns#type https://diviloper.dev/ontology#DataTag\n",
      "https://diviloper.dev/ontology/shapes#NormalizerModel http://www.w3.org/1999/02/22-rdf-syntax-ns#type http://www.w3.org/2002/07/owl#Thing\n",
      "https://diviloper.dev/ontology/shapes#NormalizerModel http://www.w3.org/ns/shacl#targetClass https://diviloper.dev/ontology/Data#NormalizerModel\n",
      "https://diviloper.dev/ontology/shapes#NormalizerModel http://www.w3.org/2002/07/owl#sameAs https://diviloper.dev/ontology/shapes#NormalizerModel\n"
     ]
    }
   ],
   "source": [
    "for s, p, o in ontology.triples((specs[1][0], None, None)):\n",
    "    print(f'{s} {p} {o}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.132094400Z",
     "start_time": "2023-07-15T18:22:35.091085900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def satisfies_shape(data_graph, shacl_graph, shape, focus):\n",
    "    conforms, g, report = validate(data_graph, shacl_graph=shacl_graph, validate_shapes=[shape], focus=focus)\n",
    "    return conforms\n",
    "\n",
    "\n",
    "def get_shape_target_class(ontology, shape):\n",
    "    return ontology.query(f\"\"\"\n",
    "        PREFIX sh: <{SH}>\n",
    "        SELECT ?targetClass\n",
    "        WHERE {{\n",
    "            <{shape}> sh:targetClass ?targetClass .\n",
    "        }}\n",
    "    \"\"\").bindings[0]['targetClass']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.138085200Z",
     "start_time": "2023-07-15T18:22:35.107085700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def get_implementation_parameters(ontology, implementation) -> dict:\n",
    "    parameters_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?parameter ?value ?order\n",
    "        WHERE {{\n",
    "            <{implementation}> dtbox:hasParameter ?parameter .\n",
    "            ?parameter dtbox:hasDefaultValue ?value ;\n",
    "                       dtbox:has_position ?order .\n",
    "        }}\n",
    "        ORDER BY ?order\n",
    "    \"\"\"\n",
    "    results = ontology.query(parameters_query).bindings\n",
    "    return {param['parameter']: (param['value'], param['order']) for param in results}\n",
    "\n",
    "\n",
    "def get_component_overriden_parameters(ontology, component) -> dict:\n",
    "    parameters_query = f\"\"\"\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?parameter ?value ?position\n",
    "        WHERE {{\n",
    "            {component.n3()} dtbox:overridesParameter ?parameterValue .\n",
    "            ?parameterValue dtbox:forParameter ?parameter ;\n",
    "                       dtbox:has_value ?value .\n",
    "            ?parameter dtbox:has_position ?position .\n",
    "        }}\n",
    "    \"\"\"\n",
    "    results = ontology.query(parameters_query).bindings\n",
    "    return {param['parameter']: (param['value'], param['position']) for param in results}\n",
    "\n",
    "\n",
    "def get_component_parameters(ontology, component) -> Dict[URIRef, Tuple[Any, int]]:\n",
    "    implementation = get_component_implementation(ontology, component)\n",
    "    implementation_params = get_implementation_parameters(ontology, implementation)\n",
    "    component_params = get_component_overriden_parameters(ontology, component)\n",
    "    implementation_params.update(component_params)\n",
    "    return implementation_params\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.138085200Z",
     "start_time": "2023-07-15T18:22:35.123086300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def add_step(graph, pipeline, task_name, implementation, parameters, order, previous_task=None, inputs=None,\n",
    "             outputs=None):\n",
    "    if outputs is None:\n",
    "        outputs = []\n",
    "    if inputs is None:\n",
    "        inputs = []\n",
    "    step = dw.term(task_name)\n",
    "    graph.add((pipeline, dtbox.hasStep, step))\n",
    "    graph.add((step, RDF.type, dtbox.Step))\n",
    "    graph.add((step, dtbox.runs, implementation))\n",
    "    graph.add((step, dtbox.has_position, Literal(order)))\n",
    "    for i, input in enumerate(inputs):\n",
    "        in_node = BNode()\n",
    "        graph.add((in_node, RDF.type, dtbox.IO))\n",
    "        graph.add((in_node, dtbox.hasData, input))\n",
    "        graph.add((in_node, dtbox.has_position, Literal(i)))\n",
    "        graph.add((step, dtbox.hasInput, in_node))\n",
    "    for o, output in enumerate(outputs):\n",
    "        out_node = BNode()\n",
    "        graph.add((out_node, RDF.type, dtbox.IO))\n",
    "        graph.add((out_node, dtbox.hasData, output))\n",
    "        graph.add((out_node, dtbox.has_position, Literal(o)))\n",
    "        graph.add((step, dtbox.hasOutput, out_node))\n",
    "    for parameter, (value, _) in parameters.items():\n",
    "        param_value = BNode()\n",
    "        graph.add((step, dtbox.hasParameterValue, param_value))\n",
    "        graph.add((param_value, dtbox.forParameter, parameter))\n",
    "        graph.add((param_value, dtbox.has_value, value))\n",
    "    if previous_task:\n",
    "        if isinstance(previous_task, list):\n",
    "            for previous in previous_task:\n",
    "                graph.add((previous, dtbox.followedBy, step))\n",
    "        else:\n",
    "            graph.add((previous_task, dtbox.followedBy, step))\n",
    "    return step"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.148087300Z",
     "start_time": "2023-07-15T18:22:35.141084600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def get_component_transformations(ontology, component) -> List:\n",
    "    transformation_query = f'''\n",
    "        PREFIX dtbox: <{dtbox}>\n",
    "        SELECT ?transformation\n",
    "        WHERE {{\n",
    "            <{component}> dtbox:hasTransformation ?transformation_list .\n",
    "            ?transformation_list rdf:rest*/rdf:first ?transformation .\n",
    "        }}\n",
    "    '''\n",
    "    transformations = ontology.query(transformation_query).bindings\n",
    "    return [x['transformation'] for x in transformations]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.171085900Z",
     "start_time": "2023-07-15T18:22:35.151086500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def copy_subgraph(source_graph: Graph, source_node: URIRef, destination_graph: Graph, destination_node: URIRef,\n",
    "                  replace_nodes: bool = True):\n",
    "    visited_nodes = set()\n",
    "    nodes_to_visit = [source_node]\n",
    "    mappings = {source_node: destination_node}\n",
    "\n",
    "    while nodes_to_visit:\n",
    "        current_node = nodes_to_visit.pop()\n",
    "        visited_nodes.add(current_node)\n",
    "        for predicate, object in source_graph.predicate_objects(current_node):\n",
    "            if predicate == OWL.sameAs:\n",
    "                continue\n",
    "            if replace_nodes and isinstance(object, IdentifiedNode):\n",
    "                if predicate == RDF.type or object in dmop:\n",
    "                    mappings[object] = object\n",
    "                else:\n",
    "                    if object not in visited_nodes:\n",
    "                        nodes_to_visit.append(object)\n",
    "                    if object not in mappings:\n",
    "                        mappings[object] = BNode()\n",
    "                destination_graph.add((mappings[current_node], predicate, mappings[object]))\n",
    "            else:\n",
    "                destination_graph.add((mappings[current_node], predicate, object))\n",
    "\n",
    "\n",
    "def annotate_io_with_spec(ontology: Graph, workflow_graph: Graph, io: URIRef, io_spec: List[URIRef]):\n",
    "    for spec in io_spec:\n",
    "        io_spec_class = next(ontology.objects(spec, SH.targetClass, True), None)\n",
    "        if io_spec_class is None or (io, RDF.type, io_spec_class) in workflow_graph:\n",
    "            continue\n",
    "        workflow_graph.add((io, RDF.type, io_spec_class))\n",
    "\n",
    "\n",
    "def annotate_ios_with_specs(ontology: Graph, workflow_graph: Graph, io: List[URIRef], specs: List[List[URIRef]]):\n",
    "    assert len(io) == len(specs), 'Number of IOs and specs must be the same'\n",
    "    for io, spec in zip(io, specs):\n",
    "        annotate_io_with_spec(ontology, workflow_graph, io, spec)\n",
    "\n",
    "\n",
    "def run_copy_transformation(ontology: Graph, workflow_graph: Graph, transformation, inputs, outputs):\n",
    "    input_index = next(ontology.objects(transformation, dtbox.copy_input, True)).value\n",
    "    output_index = next(ontology.objects(transformation, dtbox.copy_output, True)).value\n",
    "    input = inputs[input_index - 1]\n",
    "    output = outputs[output_index - 1]\n",
    "\n",
    "    copy_subgraph(workflow_graph, input, workflow_graph, output)\n",
    "\n",
    "\n",
    "def run_component_transformation(ontology: Graph, workflow_graph: Graph, component, inputs, outputs,\n",
    "                                 parameters: dict):\n",
    "    transformations = get_component_transformations(ontology, component)\n",
    "    for transformation in transformations:\n",
    "        if (transformation, RDF.type, dtbox.CopyTransformation) in ontology:\n",
    "            run_copy_transformation(ontology, workflow_graph, transformation, inputs, outputs)\n",
    "        else:\n",
    "            prefixes = f'''\n",
    "PREFIX dtbox: <{dtbox}>\n",
    "PREFIX da: <{da}>\n",
    "PREFIX rdf: <{RDF}>\n",
    "PREFIX rdfs: <{RDFS}>\n",
    "PREFIX owl: <{OWL}>\n",
    "PREFIX xsd: <{XSD}>\n",
    "PREFIX dmop: <{dmop}>\n",
    "'''\n",
    "            query = next(ontology.objects(transformation, dtbox.transformation_query, True)).value\n",
    "            query = prefixes + query\n",
    "            for i in range(len(inputs)):\n",
    "                query = query.replace(f'$input{i + 1}', f'{inputs[i].n3()}')\n",
    "            for i in range(len(outputs)):\n",
    "                query = query.replace(f'$output{i + 1}', f'{outputs[i].n3()}')\n",
    "            for param, (value, order) in parameters.items():\n",
    "                query = query.replace(f'$param{order + 1}', f'{value.toPython()}')\n",
    "                query = query.replace(f'$parameter{order + 1}', f'{value.toPython()}')\n",
    "            workflow_graph.update(query)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.198084100Z",
     "start_time": "2023-07-15T18:22:35.180087200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def step_name(workflow_name, task_order, implementation):\n",
    "    return f'{workflow_name}-step_{task_order}_{implementation.fragment.replace(\"-\", \"_\")}'\n",
    "\n",
    "\n",
    "def build_workflow_train_test(workflow_name, ontology, dataset, main_component, split_component, transformations):\n",
    "    workflow_graph = get_graph()\n",
    "    workflow = dw.term(workflow_name)\n",
    "    workflow_graph.add((workflow, RDF.type, dtbox.Workflow))\n",
    "    task_order = 0\n",
    "\n",
    "    dataset_node = dw.term(f'{workflow_name}-original_dataset')\n",
    "\n",
    "    copy_subgraph(ontology, dataset, workflow_graph, dataset_node)\n",
    "\n",
    "    split_step_name = step_name(workflow_name, task_order, split_component)\n",
    "    split_outputs = [dw[f'{split_step_name}-output_train'], dw[f'{split_step_name}-output_test']]\n",
    "    split_parameters = get_component_parameters(ontology, split_component)\n",
    "    split_step = add_step(workflow_graph, workflow,\n",
    "                          split_step_name,\n",
    "                          split_component,\n",
    "                          split_parameters,\n",
    "                          task_order,\n",
    "                          None,\n",
    "                          [dataset_node],\n",
    "                          split_outputs)\n",
    "    run_component_transformation(ontology, workflow_graph, split_component,\n",
    "                                 [dataset_node], split_outputs,\n",
    "                                 split_parameters)\n",
    "\n",
    "    task_order += 1\n",
    "\n",
    "    train_dataset_node = split_outputs[0]\n",
    "    test_dataset_node = split_outputs[1]\n",
    "\n",
    "    previous_train_step = split_step\n",
    "    previous_test_step = split_step\n",
    "\n",
    "    for train_component in [*transformations, main_component]:\n",
    "        test_component = next(ontology.objects(train_component, dtbox.hasApplier, True), train_component)\n",
    "        same = train_component == test_component\n",
    "\n",
    "        train_step_name = step_name(workflow_name, task_order, train_component)\n",
    "        test_step_name = step_name(workflow_name, task_order + 1, test_component)\n",
    "\n",
    "        train_input_specs = get_implementation_input_specs(ontology,\n",
    "                                                           get_component_implementation(ontology, train_component))\n",
    "        train_input_data_index = identify_data_io(ontology, train_input_specs, return_index=True)\n",
    "        train_transformation_inputs = [dw[f'{train_step_name}-input_{i}'] for i in range(len(train_input_specs))]\n",
    "        train_transformation_inputs[train_input_data_index] = train_dataset_node\n",
    "        annotate_ios_with_specs(ontology, workflow_graph, train_transformation_inputs,\n",
    "                                train_input_specs)\n",
    "\n",
    "        train_output_specs = get_implementation_output_specs(ontology,\n",
    "                                                             get_component_implementation(ontology, train_component))\n",
    "        train_output_model_index = identify_model_io(ontology, train_output_specs, return_index=True)\n",
    "        train_output_data_index = identify_data_io(ontology, train_output_specs, return_index=True)\n",
    "        train_transformation_outputs = [dw[f'{train_step_name}-output_{i}'] for i in range(len(train_output_specs))]\n",
    "        annotate_ios_with_specs(ontology, workflow_graph, train_transformation_outputs,\n",
    "                                train_output_specs)\n",
    "\n",
    "        train_parameters = get_component_parameters(ontology, train_component)\n",
    "        train_step = add_step(workflow_graph, workflow,\n",
    "                              train_step_name,\n",
    "                              train_component, train_parameters, task_order, previous_train_step,\n",
    "                              train_transformation_inputs,\n",
    "                              train_transformation_outputs)\n",
    "\n",
    "        previous_train_step = train_step\n",
    "\n",
    "        run_component_transformation(ontology, workflow_graph, train_component, train_transformation_inputs,\n",
    "                                     train_transformation_outputs, {})\n",
    "\n",
    "        if train_output_data_index is not None:\n",
    "            train_dataset_node = train_transformation_outputs[train_output_data_index]\n",
    "\n",
    "        task_order += 1\n",
    "\n",
    "        test_input_specs = get_implementation_input_specs(ontology,\n",
    "                                                          get_component_implementation(ontology, test_component))\n",
    "        test_input_data_index = identify_data_io(ontology, test_input_specs, return_index=True)\n",
    "        test_input_model_index = identify_model_io(ontology, test_input_specs, return_index=True)\n",
    "        test_transformation_inputs = [dw[f'{test_step_name}-input_{i}'] for i in range(len(test_input_specs))]\n",
    "        test_transformation_inputs[test_input_data_index] = test_dataset_node\n",
    "        test_transformation_inputs[test_input_model_index] = train_transformation_outputs[train_output_model_index]\n",
    "        annotate_ios_with_specs(ontology, workflow_graph, test_transformation_inputs,\n",
    "                                test_input_specs)\n",
    "\n",
    "        test_output_specs = get_implementation_output_specs(ontology,\n",
    "                                                            get_component_implementation(ontology, test_component))\n",
    "        test_output_data_index = identify_data_io(ontology, test_output_specs, return_index=True)\n",
    "        test_transformation_outputs = [dw[f'{test_step_name}-output_{i}'] for i in range(len(test_output_specs))]\n",
    "        annotate_ios_with_specs(ontology, workflow_graph, test_transformation_outputs,\n",
    "                                test_output_specs)\n",
    "\n",
    "        previous_test_steps = [previous_test_step, train_step] if not same else [previous_test_step]\n",
    "        test_parameters = get_component_parameters(ontology, test_component)\n",
    "        test_step = add_step(workflow_graph, workflow,\n",
    "                             test_step_name,\n",
    "                             test_component, test_parameters, task_order, previous_test_steps,\n",
    "                             test_transformation_inputs,\n",
    "                             test_transformation_outputs)\n",
    "\n",
    "        run_component_transformation(ontology, workflow_graph, test_component, test_transformation_inputs,\n",
    "                                     test_transformation_outputs, {})\n",
    "\n",
    "        test_dataset_node = test_transformation_outputs[test_output_data_index]\n",
    "        previous_test_step = test_step\n",
    "        task_order += 1\n",
    "\n",
    "    return workflow_graph, workflow"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.229084700Z",
     "start_time": "2023-07-15T18:22:35.209087300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Algorithm"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<Graph identifier=N0cdba7e13a9544179e2b5029b08675f8 (<class 'rdflib.graph.Graph'>)>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_graph = get_graph()\n",
    "ins = Namespace('https://diviloper.dev/intent#')\n",
    "intent_graph.add((ins.DescriptionIntent, RDF.type, dtbox.Intent))\n",
    "intent_graph.add((ins.DescriptionIntent, dtbox.overData, dd.term('penguins.csv')))\n",
    "intent_graph.add((ins.DescriptionIntent, dtbox.tackles, dabox.Description))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.242084600Z",
     "start_time": "2023-07-15T18:22:35.228085200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "log = True"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:22:35.288084800Z",
     "start_time": "2023-07-15T18:22:35.243085900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: penguins.csv\n",
      "Problem: Description\n",
      "Intent params: []\n",
      "-------------------------------------------------\n",
      "Component: component-decision_tree_learner (implementation-decision_tree_learner)\n",
      "\tInput: ['LabeledTabularDatasetShape']\n",
      "Component: component-hypertangent_svm_learner (implementation-svm_learner)\n",
      "\tInput: ['NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape', 'LabeledTabularDatasetShape', 'NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape']\n",
      "Component: component-polynomial_svm_learner (implementation-svm_learner)\n",
      "\tInput: ['NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape', 'LabeledTabularDatasetShape', 'NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape']\n",
      "Component: component-rbf_svm_learner (implementation-svm_learner)\n",
      "\tInput: ['NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape', 'LabeledTabularDatasetShape', 'NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape']\n",
      "-------------------------------------------------\n",
      "Component: component-decision_tree_learner (implementation-decision_tree_learner)\n",
      "\tData input: ['LabeledTabularDatasetShape']\n",
      "\tUnsatisfied shapes: \n",
      "\tTotal combinations: 4\n",
      "\t\tCombination 1 / 4: ['component-random_absolute_train_test_split']\n",
      "\t\tWorkflow 0: workflow_0_DescriptionIntent_172bbcda_2ecf_4f73_86f7_a5feddc07e4f\n",
      "\t\tCombination 2 / 4: ['component-random_relative_train_test_split']\n",
      "\t\tWorkflow 1: workflow_1_DescriptionIntent_fc40d8c5_ddcd_4d71_b50a_a052da904f0f\n",
      "\t\tCombination 3 / 4: ['component-top_k_absolute_train_test_split']\n",
      "\t\tWorkflow 2: workflow_2_DescriptionIntent_4da33ccd_4d26_418b_a17a_1694d7e0d84f\n",
      "\t\tCombination 4 / 4: ['component-top_k_relative_train_test_split']\n",
      "\t\tWorkflow 3: workflow_3_DescriptionIntent_8d3c735c_bca3_4f84_9326_9a7a21b6842b\n",
      "Component: component-hypertangent_svm_learner (implementation-svm_learner)\n",
      "\tData input: ['NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape', 'LabeledTabularDatasetShape', 'NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape']\n",
      "\tUnsatisfied shapes: \n",
      "\t\tNormalizedTabularDatasetShape: ['component-decimal_scaling', 'component-min_max_scaling', 'component-z_score_scaling']\n",
      "\t\tNonNullTabularDatasetShape: ['component-drop_rows_with_missing_values', 'component-mean_imputation']\n",
      "\tTotal combinations: 24\n",
      "\t\tCombination 1 / 24: ['component-random_absolute_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 4: workflow_4_DescriptionIntent_3e327f30_604d_403c_a59b_8245c70e8a71\n",
      "\t\tCombination 2 / 24: ['component-random_absolute_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 5: workflow_5_DescriptionIntent_77a42897_55ec_4bca_9d68_20b128d4246f\n",
      "\t\tCombination 3 / 24: ['component-random_absolute_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 6: workflow_6_DescriptionIntent_606c7ca8_d417_42ca_9c76_8fbffb76f893\n",
      "\t\tCombination 4 / 24: ['component-random_absolute_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 7: workflow_7_DescriptionIntent_ba157ba0_3e39_4005_a2ff_dd955489f97a\n",
      "\t\tCombination 5 / 24: ['component-random_absolute_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 8: workflow_8_DescriptionIntent_60e8b86a_3fe6_4ded_bc19_faab9228f1e8\n",
      "\t\tCombination 6 / 24: ['component-random_absolute_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 9: workflow_9_DescriptionIntent_3f6b0294_d30f_4513_934b_40de4bf113db\n",
      "\t\tCombination 7 / 24: ['component-random_relative_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 10: workflow_10_DescriptionIntent_4762afff_2235_4c9e_b3ac_6876f5b634ed\n",
      "\t\tCombination 8 / 24: ['component-random_relative_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 11: workflow_11_DescriptionIntent_814d5c9a_1d71_45d1_8cf4_b449c9b84630\n",
      "\t\tCombination 9 / 24: ['component-random_relative_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 12: workflow_12_DescriptionIntent_2d10503c_9c0e_4756_8004_ca785ac4ecea\n",
      "\t\tCombination 10 / 24: ['component-random_relative_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 13: workflow_13_DescriptionIntent_b3f4a2b6_8d19_4658_804d_45d287455b31\n",
      "\t\tCombination 11 / 24: ['component-random_relative_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 14: workflow_14_DescriptionIntent_2d82ee50_0a05_47c1_bcfe_de0b22f1ee8a\n",
      "\t\tCombination 12 / 24: ['component-random_relative_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 15: workflow_15_DescriptionIntent_b40c48c5_3842_4e82_b100_47e3ecb95ca1\n",
      "\t\tCombination 13 / 24: ['component-top_k_absolute_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 16: workflow_16_DescriptionIntent_f22cb24f_113f_4136_9fd5_547fa1a8f947\n",
      "\t\tCombination 14 / 24: ['component-top_k_absolute_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 17: workflow_17_DescriptionIntent_7a40c523_55d1_4ee9_8f02_16c16a5fc01a\n",
      "\t\tCombination 15 / 24: ['component-top_k_absolute_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 18: workflow_18_DescriptionIntent_f3ab71b2_b134_416d_b56b_1d3571bb2e12\n",
      "\t\tCombination 16 / 24: ['component-top_k_absolute_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 19: workflow_19_DescriptionIntent_4abc09ca_e7ff_41ed_9851_432952852513\n",
      "\t\tCombination 17 / 24: ['component-top_k_absolute_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 20: workflow_20_DescriptionIntent_b0285746_ad08_4b58_92c0_f0b3bbcd15b1\n",
      "\t\tCombination 18 / 24: ['component-top_k_absolute_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 21: workflow_21_DescriptionIntent_a1ea99b6_0be5_45b2_b0aa_d9527f2cdfa0\n",
      "\t\tCombination 19 / 24: ['component-top_k_relative_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 22: workflow_22_DescriptionIntent_708c1015_d2e3_4a37_a243_62034459f8c8\n",
      "\t\tCombination 20 / 24: ['component-top_k_relative_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 23: workflow_23_DescriptionIntent_50266b5b_b294_4d34_9418_01a2a73f1ea0\n",
      "\t\tCombination 21 / 24: ['component-top_k_relative_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 24: workflow_24_DescriptionIntent_e3fd04a6_ab0c_4727_a584_eca028869487\n",
      "\t\tCombination 22 / 24: ['component-top_k_relative_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 25: workflow_25_DescriptionIntent_c0d9fdee_c221_4ffe_944f_e617a92e3e5c\n",
      "\t\tCombination 23 / 24: ['component-top_k_relative_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 26: workflow_26_DescriptionIntent_b3174fd3_6178_481f_9a00_8863fcf82594\n",
      "\t\tCombination 24 / 24: ['component-top_k_relative_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 27: workflow_27_DescriptionIntent_ed29e368_a68a_456c_8bad_65a6f88eb234\n",
      "Component: component-polynomial_svm_learner (implementation-svm_learner)\n",
      "\tData input: ['NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape', 'LabeledTabularDatasetShape', 'NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape']\n",
      "\tUnsatisfied shapes: \n",
      "\t\tNormalizedTabularDatasetShape: ['component-decimal_scaling', 'component-min_max_scaling', 'component-z_score_scaling']\n",
      "\t\tNonNullTabularDatasetShape: ['component-drop_rows_with_missing_values', 'component-mean_imputation']\n",
      "\tTotal combinations: 24\n",
      "\t\tCombination 1 / 24: ['component-random_absolute_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 28: workflow_28_DescriptionIntent_00264bfe_a19c_4bbf_8992_47f795247a63\n",
      "\t\tCombination 2 / 24: ['component-random_absolute_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 29: workflow_29_DescriptionIntent_244e6fac_9c7b_46ca_8093_e631e51b8a85\n",
      "\t\tCombination 3 / 24: ['component-random_absolute_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 30: workflow_30_DescriptionIntent_7be0b74f_d010_4b4f_a9ff_358305f9015b\n",
      "\t\tCombination 4 / 24: ['component-random_absolute_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 31: workflow_31_DescriptionIntent_25cffdbe_141f_4073_8835_d823c0baaf71\n",
      "\t\tCombination 5 / 24: ['component-random_absolute_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 32: workflow_32_DescriptionIntent_2f3a446d_4ae7_48c1_9c10_94e7109724dc\n",
      "\t\tCombination 6 / 24: ['component-random_absolute_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 33: workflow_33_DescriptionIntent_22f141b7_1537_4fa3_9d96_b1384251800a\n",
      "\t\tCombination 7 / 24: ['component-random_relative_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 34: workflow_34_DescriptionIntent_4471469b_6f09_4c8a_b658_5f216ad06b7e\n",
      "\t\tCombination 8 / 24: ['component-random_relative_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 35: workflow_35_DescriptionIntent_351d3bad_8109_4718_bd46_49f29df1d287\n",
      "\t\tCombination 9 / 24: ['component-random_relative_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 36: workflow_36_DescriptionIntent_da597df6_976f_4efc_a54e_fbcdeeea6d2f\n",
      "\t\tCombination 10 / 24: ['component-random_relative_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 37: workflow_37_DescriptionIntent_67af4384_91fa_4083_aa32_6728f11f4562\n",
      "\t\tCombination 11 / 24: ['component-random_relative_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 38: workflow_38_DescriptionIntent_a2b08735_a186_4499_a06f_cee29f83d186\n",
      "\t\tCombination 12 / 24: ['component-random_relative_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 39: workflow_39_DescriptionIntent_f72dffec_6829_4c09_8ad3_90ede3f77b8d\n",
      "\t\tCombination 13 / 24: ['component-top_k_absolute_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 40: workflow_40_DescriptionIntent_3ad11b54_be94_4518_85aa_62b7ba20d897\n",
      "\t\tCombination 14 / 24: ['component-top_k_absolute_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 41: workflow_41_DescriptionIntent_816e43b8_cf1d_4ea6_877d_a0674222643f\n",
      "\t\tCombination 15 / 24: ['component-top_k_absolute_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 42: workflow_42_DescriptionIntent_b6a9d9a4_eee4_456f_b88a_8d2ae63834dc\n",
      "\t\tCombination 16 / 24: ['component-top_k_absolute_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 43: workflow_43_DescriptionIntent_d7b3a789_8734_40c4_a8d7_5c70ec2509a9\n",
      "\t\tCombination 17 / 24: ['component-top_k_absolute_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 44: workflow_44_DescriptionIntent_81ad66e0_fc7e_43b6_9669_06043be1129a\n",
      "\t\tCombination 18 / 24: ['component-top_k_absolute_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 45: workflow_45_DescriptionIntent_d6089258_58e1_45cc_b2da_80f699a6dfd0\n",
      "\t\tCombination 19 / 24: ['component-top_k_relative_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 46: workflow_46_DescriptionIntent_83723759_94f6_4cda_b72b_430d660609ab\n",
      "\t\tCombination 20 / 24: ['component-top_k_relative_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 47: workflow_47_DescriptionIntent_c701f696_f886_4510_801e_704c1e24113a\n",
      "\t\tCombination 21 / 24: ['component-top_k_relative_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 48: workflow_48_DescriptionIntent_d21dac7e_a662_4a86_af8a_36d0413ac0bf\n",
      "\t\tCombination 22 / 24: ['component-top_k_relative_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 49: workflow_49_DescriptionIntent_31e02e05_40cb_4eb4_9a46_9fb1abb92183\n",
      "\t\tCombination 23 / 24: ['component-top_k_relative_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 50: workflow_50_DescriptionIntent_7ff91723_79ce_42af_b277_c117a217d9be\n",
      "\t\tCombination 24 / 24: ['component-top_k_relative_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 51: workflow_51_DescriptionIntent_b0eb3ed5_64ec_49a6_9156_ea69d17c3cee\n",
      "Component: component-rbf_svm_learner (implementation-svm_learner)\n",
      "\tData input: ['NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape', 'LabeledTabularDatasetShape', 'NormalizedTabularDatasetShape', 'NonNullTabularDatasetShape']\n",
      "\tUnsatisfied shapes: \n",
      "\t\tNormalizedTabularDatasetShape: ['component-decimal_scaling', 'component-min_max_scaling', 'component-z_score_scaling']\n",
      "\t\tNonNullTabularDatasetShape: ['component-drop_rows_with_missing_values', 'component-mean_imputation']\n",
      "\tTotal combinations: 24\n",
      "\t\tCombination 1 / 24: ['component-random_absolute_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 52: workflow_52_DescriptionIntent_08e284c7_7da2_427a_a79c_a64f5f196bce\n",
      "\t\tCombination 2 / 24: ['component-random_absolute_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 53: workflow_53_DescriptionIntent_a89d497b_d164_4855_afe7_e477e1caacda\n",
      "\t\tCombination 3 / 24: ['component-random_absolute_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 54: workflow_54_DescriptionIntent_84276cfd_a022_4f6a_98b6_aadd25cc36ee\n",
      "\t\tCombination 4 / 24: ['component-random_absolute_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 55: workflow_55_DescriptionIntent_2db4a49d_b19e_44f2_8a02_9351e183a7b2\n",
      "\t\tCombination 5 / 24: ['component-random_absolute_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 56: workflow_56_DescriptionIntent_6fc27451_e9c0_46ef_b412_0cc8113c017f\n",
      "\t\tCombination 6 / 24: ['component-random_absolute_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 57: workflow_57_DescriptionIntent_12293f2f_50d9_4830_884b_3e5c0506db84\n",
      "\t\tCombination 7 / 24: ['component-random_relative_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 58: workflow_58_DescriptionIntent_0e9c02c5_03e5_4738_91d8_15670402c102\n",
      "\t\tCombination 8 / 24: ['component-random_relative_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 59: workflow_59_DescriptionIntent_b0e4bd97_b904_42bf_97dd_083d2551f4a9\n",
      "\t\tCombination 9 / 24: ['component-random_relative_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 60: workflow_60_DescriptionIntent_ca9f109a_71e3_46a3_b973_6f7be2cb25ed\n",
      "\t\tCombination 10 / 24: ['component-random_relative_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 61: workflow_61_DescriptionIntent_c026347e_4c7c_4835_8620_816e0e7df614\n",
      "\t\tCombination 11 / 24: ['component-random_relative_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 62: workflow_62_DescriptionIntent_a03c5af9_c6f7_4681_b6a1_130ca25b819b\n",
      "\t\tCombination 12 / 24: ['component-random_relative_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 63: workflow_63_DescriptionIntent_b07f1f3c_2a70_4043_a27f_6aef0a28a8bd\n",
      "\t\tCombination 13 / 24: ['component-top_k_absolute_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 64: workflow_64_DescriptionIntent_5c80971d_5ec4_4d70_9bb0_1ab290aac4c0\n",
      "\t\tCombination 14 / 24: ['component-top_k_absolute_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 65: workflow_65_DescriptionIntent_d86fa252_7f9b_40a8_9429_7682e1119842\n",
      "\t\tCombination 15 / 24: ['component-top_k_absolute_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 66: workflow_66_DescriptionIntent_53fabf56_e217_4f00_ba25_ba1914282c19\n",
      "\t\tCombination 16 / 24: ['component-top_k_absolute_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 67: workflow_67_DescriptionIntent_5a3ada7d_a587_487e_b8ae_75f6dc82b1ae\n",
      "\t\tCombination 17 / 24: ['component-top_k_absolute_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 68: workflow_68_DescriptionIntent_7fce34fc_ede4_43f3_8f11_731026970936\n",
      "\t\tCombination 18 / 24: ['component-top_k_absolute_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 69: workflow_69_DescriptionIntent_1bbe5454_6693_4668_9d87_6171e582972d\n",
      "\t\tCombination 19 / 24: ['component-top_k_relative_train_test_split', 'component-decimal_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 70: workflow_70_DescriptionIntent_4a924d6a_3370_4bb9_82b7_daa9d063ce14\n",
      "\t\tCombination 20 / 24: ['component-top_k_relative_train_test_split', 'component-decimal_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 71: workflow_71_DescriptionIntent_fa0006a3_e0af_4f25_9d0d_2b4a8dbc0a88\n",
      "\t\tCombination 21 / 24: ['component-top_k_relative_train_test_split', 'component-min_max_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 72: workflow_72_DescriptionIntent_451611ec_6561_4e5c_b77c_217d716914fa\n",
      "\t\tCombination 22 / 24: ['component-top_k_relative_train_test_split', 'component-min_max_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 73: workflow_73_DescriptionIntent_23376aea_7e35_4c9a_a712_670582124e3b\n",
      "\t\tCombination 23 / 24: ['component-top_k_relative_train_test_split', 'component-z_score_scaling', 'component-drop_rows_with_missing_values']\n",
      "\t\tWorkflow 74: workflow_74_DescriptionIntent_a918d35f_1587_496a_b2fb_b73488d526e0\n",
      "\t\tCombination 24 / 24: ['component-top_k_relative_train_test_split', 'component-z_score_scaling', 'component-mean_imputation']\n",
      "\t\tWorkflow 75: workflow_75_DescriptionIntent_b5c909b7_303f_430c_b3f3_aaab5a801a38\n"
     ]
    }
   ],
   "source": [
    "dataset, problem, intent_params, intent_iri = get_intent_info(intent_graph)\n",
    "folder = f'./workflows/{datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")}/'\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "if log:\n",
    "    print(f'Dataset: {dataset.fragment}')\n",
    "    print(f'Problem: {problem.fragment}')\n",
    "    print(f'Intent params: {intent_params}')\n",
    "    print('-------------------------------------------------')\n",
    "\n",
    "comps = get_potential_implementations(ontology, problem, [x['param'] for x in intent_params])\n",
    "components = [\n",
    "    (c, impl, inputs)\n",
    "    for impl, inputs in comps\n",
    "    for c in get_implementation_components(ontology, impl)\n",
    "]\n",
    "if log:\n",
    "    for component, implementation, inputs in components:\n",
    "        print(f'Component: {component.fragment} ({implementation.fragment})')\n",
    "        for im_input in inputs:\n",
    "            print(f'\\tInput: {[x.fragment for x in im_input]}')\n",
    "    print('-------------------------------------------------')\n",
    "\n",
    "workflow_order = 0\n",
    "\n",
    "split_components = [\n",
    "    dabox.term('component-random_absolute_train_test_split'),\n",
    "    dabox.term('component-random_relative_train_test_split'),\n",
    "    dabox.term('component-top_k_absolute_train_test_split'),\n",
    "    dabox.term('component-top_k_relative_train_test_split'),\n",
    "]\n",
    "\n",
    "for component, implementation, inputs in components:\n",
    "    if log:\n",
    "        print(f'Component: {component.fragment} ({implementation.fragment})')\n",
    "    shapes_to_satisfy = identify_data_io(ontology, inputs)\n",
    "    assert shapes_to_satisfy is not None and len(shapes_to_satisfy) > 0\n",
    "    if log:\n",
    "        print(f'\\tData input: {[x.fragment for x in shapes_to_satisfy]}')\n",
    "\n",
    "    unsatisfied_shapes = [shape for shape in shapes_to_satisfy if\n",
    "                          not satisfies_shape(ontology, ontology, shape, dataset)]\n",
    "\n",
    "    available_transformations = {\n",
    "        shape: find_components_to_satisfy_shape(ontology, shape, only_learners=True)\n",
    "        for shape in unsatisfied_shapes\n",
    "    }\n",
    "\n",
    "    if log:\n",
    "        print(f'\\tUnsatisfied shapes: ')\n",
    "        for shape, comps in available_transformations.items():\n",
    "            print(f'\\t\\t{shape.fragment}: {[x.fragment for x in comps]}')\n",
    "\n",
    "    transformation_combinations = list(itertools.product(split_components, *available_transformations.values()))\n",
    "    # TODO - check if the combination is valid and whether further transformations are needed\n",
    "\n",
    "    if log:\n",
    "        print(f'\\tTotal combinations: {len(transformation_combinations)}')\n",
    "\n",
    "    for i, transformation_combination in enumerate(transformation_combinations):\n",
    "        if log:\n",
    "            print(\n",
    "                f'\\t\\tCombination {i + 1} / {len(transformation_combinations)}: {[x.fragment for x in transformation_combination]}')\n",
    "\n",
    "        workflow_name = f'workflow_{workflow_order}_{intent_iri.fragment}_{uuid.uuid4()}'.replace('-', '_')\n",
    "        wg, w = build_workflow_train_test(workflow_name, ontology, dataset, component, transformation_combination[0],\n",
    "                                          transformation_combination[1:])\n",
    "        if log:\n",
    "            print(f'\\t\\tWorkflow {workflow_order}: {w.fragment}')\n",
    "        wg.serialize(f'{folder}{workflow_name}.ttl', format='turtle')\n",
    "        workflow_order += 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:27:46.598664300Z",
     "start_time": "2023-07-15T18:27:10.850764500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nPREFIX dtbox: <https://diviloper.dev/ontology#>\\nPREFIX da: <https://diviloper.dev/ontology/ABOX#>\\nPREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\\nPREFIX owl: <http://www.w3.org/2002/07/owl#>\\nPREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\\nPREFIX dmop: <http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#>\\n\\nINSERT {\\n    ?column dmop:hasMeanValue 0;\\n            dmop:hasStandardDeviation 1;\\n            dmop:isNormalized true.\\n}\\nWHERE {\\n    <https://diviloper.dev/ontology/Workflow#workflow_0_DescriptionIntent_9ed1e6f1_6549_4314_ac7d_3e2f73e05e3f-step_2_component_normalizer_applier-output_1> dmop:hasColumn ?column .\\n    ?column dmop:isFeature true ;\\n    <https://diviloper.dev/ontology/Workflow#workflow_0_DescriptionIntent_9ed1e6f1_6549_4314_ac7d_3e2f73e05e3f-step_1_component_decimal_scaling-output_1> da:normalizationMode \"ZScore\";\\n}\\n\\n'"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PREFIX dtbox: <https://diviloper.dev/ontology#>\n",
    "PREFIX da: <https://diviloper.dev/ontology/ABOX#>\n",
    "PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>\n",
    "PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
    "PREFIX owl: <http://www.w3.org/2002/07/owl#>\n",
    "PREFIX xsd: <http://www.w3.org/2001/XMLSchema#>\n",
    "PREFIX dmop: <http://www.e-lico.eu/ontologies/dmo/DMOP/DMOP.owl#>\n",
    "\n",
    "INSERT {\n",
    "    ?column dmop:hasMeanValue 0;\n",
    "            dmop:hasStandardDeviation 1;\n",
    "            dmop:isNormalized true.\n",
    "}\n",
    "WHERE {\n",
    "    <https://diviloper.dev/ontology/Workflow#workflow_0_DescriptionIntent_9ed1e6f1_6549_4314_ac7d_3e2f73e05e3f-step_2_component_normalizer_applier-output_1> dmop:hasColumn ?column .\n",
    "    ?column dmop:isFeature true ;\n",
    "    <https://diviloper.dev/ontology/Workflow#workflow_0_DescriptionIntent_9ed1e6f1_6549_4314_ac7d_3e2f73e05e3f-step_1_component_decimal_scaling-output_1> da:normalizationMode \"ZScore\";\n",
    "}\n",
    "\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-15T18:23:09.651867Z",
     "start_time": "2023-07-15T18:23:09.636868200Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
